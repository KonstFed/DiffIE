# Training configuration for diffusion-based OpenIE model

# Trainer configuration (optimizer, device, etc.)
trainer:
  device: null  # null = auto-detect (cuda if available, else cpu)
  learning_rate: 1e-4
  weight_decay: 0.01
  max_grad_norm: 1.0

# Model configuration (encoder, label_mapper, scheduler, denoiser)
model:
  # BERT encoder for token embeddings
  encoder:
    model_name: "bert-base-uncased"
    freeze: true
    add_special_tokens: true
  
  # Label mapper: converts label indices to embeddings
  label_mapper:
    num_classes: 4  # O, Subject, Object, Predicate
    embedding_dim: 256
  
  # Diffusion scheduler: handles noise schedule
  scheduler:
    num_steps: 1000
    beta_start: 0.0001
    beta_end: 0.02
  
  # Denoiser: predicts x0 from noisy x_t
  denoiser:
    x_dim: 256  # Must match label_mapper.embedding_dim
    bert_dim: 768  # Must match BERT encoder output (bert-base-uncased = 768)
    num_steps: 1000  # Must match scheduler.num_steps
    d_model: 256
    n_layers: 4
    n_heads: 8
    d_ff: 1024

# Data loading configuration
data:
  dataset_name: "SequenceLSOEIDataset"
  tokenizer_name: "bert-base-uncased"
  batch_size: 32
  num_workers: 4
  pad_token_id: 0
  pad_label_idx: 0

# Training hyperparameters
num_epochs: 100
log_interval: 100  # Log metrics every N steps
save_path: null  # Path to save checkpoints (null = don't save)
save_interval: 5 # Save checkpoint every N epochs
val_full_interval: 5  # Run full validation (with metrics) every N epochs
num_classes: 4  # O, Subject, Object, Predicate
